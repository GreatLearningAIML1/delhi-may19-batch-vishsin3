{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxMP_DeLoHzf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f6d993c3-b227-4020-8bf6-34c921f4963a"
      },
      "source": [
        "print(x_test.shape)\n",
        "print(x_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n",
            "(60000, 28, 28)\n",
            "(10000,)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a44ecf08-9dd6-44a0-b885-059c7fd1b2d6"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cG6DEpBuslz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07b08d8f-8f78-4285-9491-76bb3be3b924"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "y_train= keras.utils.to_categorical(y_train,10)\n",
        "y_test= keras.utils.to_categorical(y_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e84ca050-7b47-4b59-fb7b-079713424c2f"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "x_train.shape[0]\n",
        "\n",
        "x_train= x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okwo_SB5JjwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #reshaping done in the above cell."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTbz2QimyonV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EVVHCOBzEQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "7e5a6ae6-0394-4ab8-a146-8494232cfc05"
      },
      "source": [
        "# Define model\n",
        "    model1 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model1.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model1.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model1.add(Convolution2D(32, 3, 3))\n",
        "    model1.add(Activation('relu'))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model1.add(Flatten())\n",
        "    model1.add(Dense(128))\n",
        "    model1.add(Activation('relu'))\n",
        "\n",
        "    # Prediction Layer\n",
        "    model1.add(Dense(10))\n",
        "    model1.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model\n",
        "    model1.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "              validation_data=(x_test, y_test), callbacks=callback_list)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.3667 - acc: 0.8683 - val_loss: 0.3088 - val_acc: 0.8850\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.2227 - acc: 0.9175 - val_loss: 0.2518 - val_acc: 0.9113\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.1565 - acc: 0.9421 - val_loss: 0.2478 - val_acc: 0.9144\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.1044 - acc: 0.9608 - val_loss: 0.2747 - val_acc: 0.9182\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0689 - acc: 0.9742 - val_loss: 0.3138 - val_acc: 0.9119\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0448 - acc: 0.9837 - val_loss: 0.3785 - val_acc: 0.9171\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0325 - acc: 0.9885 - val_loss: 0.4146 - val_acc: 0.9115\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0234 - acc: 0.9915 - val_loss: 0.4889 - val_acc: 0.9093\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0211 - acc: 0.9924 - val_loss: 0.5045 - val_acc: 0.9124\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0df4a83780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "a0481760-59b6-4313-eb23-94f006ba540a"
      },
      "source": [
        "# Define Model\n",
        "    model2 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # Max Pooling\n",
        "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    # Dropout\n",
        "    model2.add(Dropout(0.25))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(128))\n",
        "    model2.add(Activation('relu'))\n",
        "    \n",
        "\n",
        "    # Prediction Layer\n",
        "    model2.add(Dense(10))\n",
        "    model2.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model\n",
        "    model2.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "              validation_data=(x_test, y_test), callbacks=callback_list)\n",
        "    "
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.3931 - acc: 0.8583 - val_loss: 0.3016 - val_acc: 0.8913\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.2569 - acc: 0.9060 - val_loss: 0.2521 - val_acc: 0.9100\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.2108 - acc: 0.9223 - val_loss: 0.2347 - val_acc: 0.9152\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.1767 - acc: 0.9341 - val_loss: 0.2245 - val_acc: 0.9214\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.1509 - acc: 0.9436 - val_loss: 0.2254 - val_acc: 0.9219\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.1286 - acc: 0.9507 - val_loss: 0.2351 - val_acc: 0.9230\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.1105 - acc: 0.9578 - val_loss: 0.2484 - val_acc: 0.9213\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0930 - acc: 0.9651 - val_loss: 0.2518 - val_acc: 0.9245\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0828 - acc: 0.9686 - val_loss: 0.2709 - val_acc: 0.9204\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0720 - acc: 0.9726 - val_loss: 0.2832 - val_acc: 0.9183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0de00470b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.01,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.01,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "    \n",
        "# Prepare the generator\n",
        "datagen.fit(x_train)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "511dae19-33b7-4b65-900c-0360b6560c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvBbRPqCcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "61210e1b-4a98-4fcb-8b29-f50b32cab50a"
      },
      "source": [
        "model2.fit_generator(datagen.flow(x_train, y_train,batch_size=32),\n",
        "                    samples_per_epoch=x_train.shape[0],\n",
        "                    nb_epoch=10,\n",
        "                    validation_data=(x_test, y_test), callbacks=callback_list)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  12/1875 [..............................] - ETA: 20s - loss: 2.4767 - acc: 0.4349"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5007 - acc: 0.8207 - val_loss: 0.2868 - val_acc: 0.8994\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3657 - acc: 0.8674 - val_loss: 0.2652 - val_acc: 0.9092\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3318 - acc: 0.8770 - val_loss: 0.2616 - val_acc: 0.9120\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3091 - acc: 0.8868 - val_loss: 0.2527 - val_acc: 0.9144\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2938 - acc: 0.8918 - val_loss: 0.2660 - val_acc: 0.9138\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.2849 - acc: 0.8949 - val_loss: 0.2605 - val_acc: 0.9124\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2709 - acc: 0.9005 - val_loss: 0.2503 - val_acc: 0.9154\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2666 - acc: 0.9021 - val_loss: 0.2682 - val_acc: 0.9136\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2576 - acc: 0.9050 - val_loss: 0.2482 - val_acc: 0.9194\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2510 - acc: 0.9070 - val_loss: 0.2668 - val_acc: 0.9114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0df4afb748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "59de6a39-48b0-4e6a-b069-b53e3b83e54e"
      },
      "source": [
        "loss_and_metrics = model2.evaluate(x_train, y_train)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 55us/step\n",
            "[0.15105578390012184, 0.9436]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwVWNQC2qZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10, mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ1WzrXd4WNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x1_train, y1_train), (x1_test, y1_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Pht1ggHuiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1_train = x1_train.reshape(x1_train.shape[0], 32,32,3).astype('float32')\n",
        "x1_test = x1_test.reshape(x1_test.shape[0], 32, 32, 3).astype('float32')\n",
        "x1_train.shape[0]\n",
        "\n",
        "x1_train= x1_train / 255\n",
        "x1_test = x1_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n28ccU6Hp6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y1_train= keras.utils.to_categorical(y1_train,10)\n",
        "y1_test= keras.utils.to_categorical(y1_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen1 = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.01,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.01,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "    \n",
        "# Prepare the generator\n",
        "datagen1.fit(x1_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZIF4CbRL03o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NpCYXXbWL1MJ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lza8H_9QSxdt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4TnFkZrK5bB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "33e384ba-6bcc-4450-8744-c4837dbf1bcf"
      },
      "source": [
        "# Define Model\n",
        "    model3 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model3.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model3.add(Convolution2D(32, 3, 3))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "    # 3rd Conv Layer\n",
        "    model3.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "  \n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model3.add(Flatten())\n",
        "    model3.add(Dense(128))\n",
        "    model3.add(Activation('relu'))\n",
        "    \n",
        "\n",
        "    # Prediction Layer\n",
        "    model3.add(Dense(10))\n",
        "    model3.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3...)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSw8Bv2_4hb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "18a6c4f1-e933-472c-a45e-239939015d82"
      },
      "source": [
        "model3.fit_generator(datagen1.flow(x1_train, y1_train,batch_size=32),\n",
        "                    samples_per_epoch=x_train.shape[0],\n",
        "                    nb_epoch=10,\n",
        "                    validation_data=(x1_test, y1_test), callbacks=callback_list)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1562, epochs=10)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1562/1562 [==============================] - 30s 19ms/step - loss: 1.6010 - acc: 0.4233 - val_loss: 1.3340 - val_acc: 0.5171\n",
            "Epoch 2/10\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 1.3491 - acc: 0.5191 - val_loss: 1.2701 - val_acc: 0.5486\n",
            "Epoch 3/10\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 1.2447 - acc: 0.5574 - val_loss: 1.0863 - val_acc: 0.6171\n",
            "Epoch 4/10\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 1.1735 - acc: 0.5842 - val_loss: 1.0792 - val_acc: 0.6213\n",
            "Epoch 5/10\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 1.1239 - acc: 0.6030 - val_loss: 1.0918 - val_acc: 0.6130\n",
            "Epoch 6/10\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 1.0909 - acc: 0.6129 - val_loss: 1.0398 - val_acc: 0.6471\n",
            "Epoch 7/10\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 1.0609 - acc: 0.6255 - val_loss: 1.0157 - val_acc: 0.6426\n",
            "Epoch 8/10\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 1.0408 - acc: 0.6332 - val_loss: 1.0536 - val_acc: 0.6442\n",
            "Epoch 9/10\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 1.0116 - acc: 0.6422 - val_loss: 1.0627 - val_acc: 0.6386\n",
            "Epoch 10/10\n",
            "1562/1562 [==============================] - 28s 18ms/step - loss: 0.9948 - acc: 0.6476 - val_loss: 1.0281 - val_acc: 0.6523\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0dcce04128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "fba02808-05c4-4597-b0b0-24bab9d0ce0c"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen1.flow(x1_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNBE12oO2MgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqF2O0giU2Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}